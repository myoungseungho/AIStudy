<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CNN은 왜 이미지에 강해? - Section 5</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: 'Pretendard', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background: #fafafa;
            color: #333;
            line-height: 1.9;
        }
        .container { max-width: 800px; margin: 0 auto; padding: 60px 20px; }
        .breadcrumb { margin-bottom: 24px; font-size: 0.9rem; }
        .breadcrumb a { color: #666; text-decoration: none; }
        .breadcrumb a:hover { text-decoration: underline; }
        .breadcrumb span { color: #999; margin: 0 8px; }
        .header { margin-bottom: 48px; }
        .topic-number {
            display: inline-block;
            background: #00BCD4;
            color: white;
            padding: 6px 16px;
            border-radius: 20px;
            font-size: 0.85rem;
            font-weight: 600;
            margin-bottom: 16px;
        }
        .header h1 { font-size: 2rem; font-weight: 700; color: #111; margin-bottom: 12px; }
        .header p { color: #666; font-size: 1.1rem; }
        .conversation {
            background: white;
            border-radius: 16px;
            padding: 32px;
            margin: 32px 0;
            border: 1px solid #e0e0e0;
        }
        .conversation h2 {
            font-size: 1.3rem;
            color: #00BCD4;
            margin-bottom: 24px;
            padding-bottom: 12px;
            border-bottom: 2px solid #e0f7fa;
        }
        .chat { margin-bottom: 20px; }
        .q {
            background: #fff3e0;
            border-left: 4px solid #ff9800;
            padding: 16px 20px;
            margin: 16px 0;
            border-radius: 0 12px 12px 0;
            font-weight: 500;
        }
        .q::before { content: "Q. "; color: #e65100; font-weight: 700; }
        .a {
            padding: 8px 0 8px 20px;
            border-left: 4px solid #e0e0e0;
            margin: 12px 0;
        }
        .a p { margin-bottom: 12px; }
        .a p:last-child { margin-bottom: 0; }
        .highlight {
            background: #e3f2fd;
            padding: 2px 8px;
            border-radius: 4px;
            font-weight: 600;
            color: #1565c0;
        }
        .key-point {
            background: #e0f7fa;
            padding: 2px 8px;
            border-radius: 4px;
            font-weight: 600;
            color: #00838f;
        }
        .warning {
            background: #ffcdd2;
            padding: 2px 8px;
            border-radius: 4px;
            font-weight: 600;
            color: #c62828;
        }
        .code-block {
            background: #263238;
            border-radius: 8px;
            padding: 16px 20px;
            margin: 16px 0;
            font-family: 'Consolas', monospace;
            font-size: 0.9rem;
            color: #eceff1;
            overflow-x: auto;
            line-height: 1.6;
            white-space: pre-wrap;
        }
        .compare-table {
            width: 100%;
            border-collapse: collapse;
            margin: 16px 0;
            font-size: 0.9rem;
        }
        .compare-table th, .compare-table td {
            padding: 12px;
            border: 1px solid #e0e0e0;
            text-align: left;
        }
        .compare-table th { background: #f5f5f5; font-weight: 600; }
        .summary-box {
            background: linear-gradient(135deg, #00BCD4 0%, #26C6DA 100%);
            border-radius: 16px;
            padding: 32px;
            color: white;
            margin: 32px 0;
        }
        .summary-box h3 { font-size: 1.2rem; margin-bottom: 20px; }
        .summary-box ul { list-style: none; }
        .summary-box li {
            padding: 8px 0;
            padding-left: 24px;
            position: relative;
        }
        .summary-box li::before {
            content: "→";
            position: absolute;
            left: 0;
            color: #b2ebf2;
        }
        .nav-links {
            display: flex;
            justify-content: space-between;
            margin-top: 60px;
            padding-top: 24px;
            border-top: 1px solid #e0e0e0;
        }
        .nav-links a { color: #00BCD4; text-decoration: none; font-weight: 500; }
        .nav-links a:hover { text-decoration: underline; }
    </style>
</head>
<body>
    <div class="container">
        <nav class="breadcrumb">
            <a href="../../">AI 공부</a>
            <span>/</span>
            <a href="../">Section 5</a>
            <span>/</span>
            Topic 05
        </nav>

        <header class="header">
            <div class="topic-number">TOPIC 05</div>
            <h1>CNN은 왜 이미지에 강해?</h1>
            <p>Q. 일반 신경망이랑 뭐가 달라?</p>
        </header>

        <!-- Part 1: 일반 신경망의 문제 -->
        <div class="conversation">
            <h2>Part 1. 일반 신경망으로는 안 돼?</h2>

            <div class="chat">
                <div class="q">일반 신경망(MLP)으로 이미지를 학습하면 안 돼?</div>
                <div class="a">
                    <p>할 수는 있어. 하지만 <span class="warning">엄청 비효율적이야.</span></p>
                </div>
            </div>

            <div class="code-block">일반 신경망의 문제점:

문제 1: 파라미터 폭발
→ 224×224 RGB 이미지 = 150,528개 픽셀
→ 첫 은닉층 1000개 뉴런이면?
→ 파라미터 = 150,528 × 1000 = 1억 5천만 개!

문제 2: 공간 정보 손실
→ 이미지를 1차원으로 펼쳐야 함
→ "왼쪽 위에 눈이 있다" 같은 위치 정보 사라짐

문제 3: 위치에 민감
→ 고양이가 왼쪽에 있으면 학습
→ 오른쪽에 있으면 새로운 패턴으로 인식</div>

            <div class="chat">
                <div class="a">
                    <p>이해됐어?</p>
                    <p><span class="highlight">일반 신경망은 이미지의 특성을 전혀 활용 못 해.</span></p>
                </div>
            </div>
        </div>

        <!-- Part 2: CNN의 세 가지 핵심 -->
        <div class="conversation">
            <h2>Part 2. CNN은 뭐가 다른데?</h2>

            <div class="chat">
                <div class="q">CNN은 어떻게 이 문제를 해결해?</div>
                <div class="a">
                    <p><span class="key-point">세 가지 핵심 아이디어</span>가 있어.</p>
                </div>
            </div>

            <div class="code-block">CNN의 3대 핵심:

1. 국소 연결 (Local Connectivity)
→ 전체를 보지 않고 작은 영역만 봄
→ 3×3 필터로 주변 9개 픽셀만 연결
→ 파라미터 대폭 감소

2. 파라미터 공유 (Weight Sharing)
→ 같은 필터를 이미지 전체에 재사용
→ "왼쪽 위 엣지 검출기 = 오른쪽 아래 엣지 검출기"
→ 위치에 관계없이 패턴 인식

3. 계층적 학습 (Hierarchical Learning)
→ 층이 깊어질수록 복잡한 특징 학습
→ 엣지 → 코너 → 부분 → 전체</div>

            <div class="chat">
                <div class="a">
                    <p>이 세 가지가 <strong>이미지의 본질</strong>과 딱 맞아떨어져.</p>
                </div>
            </div>
        </div>

        <!-- Part 3: 구조 비교 -->
        <div class="conversation">
            <h2>Part 3. 구조를 비교해보자</h2>

            <table class="compare-table">
                <tr>
                    <th>특징</th>
                    <th>일반 신경망 (MLP)</th>
                    <th>CNN</th>
                </tr>
                <tr>
                    <td><strong>입력</strong></td>
                    <td>1차원 벡터<br>[150,528]</td>
                    <td>3차원 텐서<br>(224, 224, 3)</td>
                </tr>
                <tr>
                    <td><strong>연결</strong></td>
                    <td>전체 연결<br>(Fully Connected)</td>
                    <td>국소 연결<br>(Local)</td>
                </tr>
                <tr>
                    <td><strong>파라미터</strong></td>
                    <td>수억 개</td>
                    <td>수천~수만 개</td>
                </tr>
                <tr>
                    <td><strong>위치 불변성</strong></td>
                    <td>없음</td>
                    <td>있음</td>
                </tr>
                <tr>
                    <td><strong>공간 정보</strong></td>
                    <td>손실됨</td>
                    <td>보존됨</td>
                </tr>
                <tr>
                    <td><strong>학습 속도</strong></td>
                    <td>느림</td>
                    <td>빠름</td>
                </tr>
            </table>

            <div class="chat">
                <div class="q">그럼 CNN이 무조건 좋은 거네?</div>
                <div class="a">
                    <p><span class="highlight">이미지에 대해서는 압도적으로 좋아.</span></p>
                    <p>하지만 일반 데이터(표 형태)에는 MLP가 더 나을 수도 있어.</p>
                </div>
            </div>
        </div>

        <!-- Part 4: 계층적 학습 -->
        <div class="conversation">
            <h2>Part 4. 계층적 학습이 핵심</h2>

            <div class="chat">
                <div class="q">층이 깊어지면 뭐가 달라져?</div>
                <div class="a">
                    <p><span class="key-point">점점 더 복잡한 특징을 배워.</span></p>
                </div>
            </div>

            <div class="code-block">CNN 학습 과정:

Layer 1 (Low-level):
→ 엣지, 코너, 색상 변화 같은 단순한 패턴
→ 필터: 수직선, 수평선, 대각선

Layer 2-3 (Mid-level):
→ 간단한 도형, 질감
→ 필터: 눈 모양, 귀 모양, 털 패턴

Layer 4-5 (High-level):
→ 복잡한 객체 부분
→ 필터: 얼굴, 다리, 몸통

마지막 층:
→ 완전한 객체
→ "고양이", "강아지", "자동차"</div>

            <div class="chat">
                <div class="a">
                    <p>이해됐어?</p>
                    <p>마치 <strong>레고 블록</strong>처럼:</p>
                    <p>→ 작은 조각(엣지) → 중간 조각(부분) → 완성품(객체)</p>
                    <p>이렇게 단계적으로 조합하는 거야.</p>
                </div>
            </div>
        </div>

        <!-- Part 5: 왜 이게 잘 작동할까? -->
        <div class="conversation">
            <h2>Part 5. 왜 이 방식이 효과적이야?</h2>

            <div class="chat">
                <div class="q">사람도 이렇게 봐?</div>
                <div class="a">
                    <p><span class="highlight">놀랍게도 비슷해!</span></p>
                    <p>사람의 시각 피질(Visual Cortex)도 계층적으로 작동해.</p>
                </div>
            </div>

            <div class="code-block">사람의 시각 처리:

V1 영역 (1차 시각 피질):
→ 선의 방향, 엣지 감지
→ CNN의 첫 번째 층과 유사

V2 영역:
→ 색상, 질감, 간단한 형태
→ CNN의 중간 층과 유사

V4, IT 영역:
→ 복잡한 객체 인식
→ CNN의 깊은 층과 유사


놀라운 발견:
→ CNN이 사람 뇌를 모방한 게 아니라
→ 이미지 특성상 "이렇게 하는 게 최적"
→ 진화와 AI가 같은 해답을 찾음!</div>

            <div class="chat">
                <div class="a">
                    <p>그래서 CNN은 <strong>"생물학적으로 그럴듯한(biologically plausible)"</strong> 모델이라고 불려.</p>
                </div>
            </div>
        </div>

        <!-- Part 6: 실제 성능 차이 -->
        <div class="conversation">
            <h2>Part 6. 실제로 얼마나 차이 나?</h2>

            <div class="chat">
                <div class="q">구체적인 수치로 보여줘</div>
                <div class="a">
                    <p>ImageNet 데이터셋으로 비교해보면:</p>
                </div>
            </div>

            <div class="code-block">ImageNet 분류 정확도:

일반 신경망 (MLP):
→ 정확도: ~50%
→ 파라미터: 수억 개
→ 학습 시간: 매우 오래 걸림
→ 과적합 심함


AlexNet (CNN, 2012):
→ 정확도: 63%
→ 파라미터: 6천만 개
→ ImageNet 우승


ResNet-50 (CNN, 2015):
→ 정확도: 76%
→ 파라미터: 2,500만 개
→ 사람 수준


EfficientNet (CNN, 2019):
→ 정확도: 84%
→ 파라미터: 660만 개
→ 사람을 뛰어넘음</div>

            <div class="chat">
                <div class="a">
                    <p>보이지?</p>
                    <p><span class="key-point">CNN은 파라미터는 적은데 성능은 압도적이야.</span></p>
                    <p>이미지 인식에서 CNN은 선택이 아니라 <strong>필수</strong>야.</p>
                </div>
            </div>
        </div>

        <!-- 핵심 정리 -->
        <div class="summary-box">
            <h3>핵심 정리</h3>
            <ul>
                <li><strong>국소 연결</strong> - 전체가 아닌 작은 영역만 연결해 파라미터 감소</li>
                <li><strong>파라미터 공유</strong> - 같은 필터를 재사용해 위치 불변성 획득</li>
                <li><strong>계층적 학습</strong> - 단순→복잡한 특징을 단계적으로 학습</li>
                <li><strong>공간 정보 보존</strong> - 2D/3D 구조 유지로 이미지 특성 활용</li>
                <li><strong>생물학적 유사성</strong> - 사람 시각 피질과 작동 원리 비슷</li>
                <li><strong>압도적 성능</strong> - 일반 신경망 대비 정확도 높고 파라미터 적음</li>
            </ul>
        </div>

        <div class="nav-links">
            <a href="../topic04/">← 이전: 합성곱(Convolution)이 뭐야?</a>
            <a href="../topic06/">다음: 필터는 어떻게 학습돼? →</a>
        </div>
    </div>
</body>
</html>
